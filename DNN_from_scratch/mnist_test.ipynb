{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import os \n",
    "from time import time\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float64\") / 255.0\n",
    "x_test  = x_test.astype('float64') / 255.0\n",
    "x_train = tf.convert_to_tensor(x_train)\n",
    "x_test = tf.convert_to_tensor(x_test)\n",
    "x_train = (x_train.numpy())\n",
    "x_test = (x_test.numpy())\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test  = np.expand_dims(x_test , axis=3)\n",
    "\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test  = y_test.reshape(-1)\n",
    "def processing(Y, n):\n",
    "    y = np.zeros((Y.shape[0], n))\n",
    "    for i in range(Y.shape[0]):\n",
    "        y[i, int(Y[i])] = 1\n",
    "    return y\n",
    "\n",
    "y_train = processing(y_train, 10)\n",
    "y_test  = processing(y_test , 10)\n",
    "\n",
    "from DNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 Cost: 2.3022920793425707; Accuracy: 0.09863333333333334\n",
      "time: 1459.002151966095\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, output\u001b[38;5;241m=\u001b[39moutput)\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mLoss\u001b[38;5;241m.\u001b[39mCrossEntropy, optimizer\u001b[38;5;241m=\u001b[39mOptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m))\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\DNN.py:85\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x_train, y_train, batch_size, epochs, iters, verbose)\u001b[0m\n\u001b[0;32m     83\u001b[0m y \u001b[38;5;241m=\u001b[39m y_batch\n\u001b[0;32m     84\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mderivative(y_hat, y)\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mback_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epochs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\Layer.py:104\u001b[0m, in \u001b[0;36mLayer.back_propagation\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m change_b \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m#previous layer call back propagation\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprev_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mback_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\Layer.py:93\u001b[0m, in \u001b[0;36mLayer.back_propagation\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m     90\u001b[0m d_b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(e\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 93\u001b[0m     d_w \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mouter\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprev_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m d_b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(e, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     96\u001b[0m e \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mT, e\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\numeric.py:925\u001b[0m, in \u001b[0;36mouter\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m    923\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a)\n\u001b[0;32m    924\u001b[0m b \u001b[38;5;241m=\u001b[39m asarray(b)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input = Input(shape=(28, 28, 1))\n",
    "conv2d1 = Layer.Conv2D(filters=16, kernel_size=3, padding=1, activation='ReLU', prev_layer=input)\n",
    "maxpooling1 = Layer.MaxPool2D(pool_size=2, prev_layer=conv2d1)\n",
    "conv2d2 = Layer.Conv2D(filters=32, kernel_size=3, padding=1, activation='ReLU', prev_layer=maxpooling1)\n",
    "maxpooling2 = Layer.MaxPool2D(pool_size=2, prev_layer=conv2d2)\n",
    "\n",
    "flatten = Layer.Flatten(prev_layer=maxpooling2)\n",
    "layer1 = Layer.Layer(shape=64, activation='ReLU', prev_layer=flatten)\n",
    "output = Layer.Layer(shape=10, activation='softmax', prev_layer=layer1)\n",
    "model = Model(input=input, output=output)\n",
    "model.compile(loss=Loss.CrossEntropy, optimizer=Optimizers.SGD(learning_rate=0.0001, momentum=0.9))\n",
    "\n",
    "model.fit(x_train=x_train, y_train=y_train, batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 Cost: 0.6040950675776285; Accuracy: 0.816\n",
      "epoch: 2 Cost: 0.699783296085795; Accuracy: 0.762\n",
      "epoch: 3 Cost: 0.5571612304418748; Accuracy: 0.823\n",
      "epoch: 4 Cost: 0.5965299567922426; Accuracy: 0.791\n",
      "epoch: 5 Cost: 0.6076127824776858; Accuracy: 0.816\n",
      "epoch: 6 Cost: 0.5600028427665359; Accuracy: 0.822\n",
      "epoch: 7 Cost: 0.6730055067115019; Accuracy: 0.779\n",
      "epoch: 8 Cost: 0.5389390070979219; Accuracy: 0.829\n",
      "epoch: 9 Cost: 0.568602915220156; Accuracy: 0.823\n",
      "epoch: 10 Cost: 0.5892609550182033; Accuracy: 0.817\n",
      "epoch: 11 Cost: 0.5338502099377065; Accuracy: 0.845\n",
      "epoch: 12 Cost: 0.5290327728810917; Accuracy: 0.829\n",
      "epoch: 13 Cost: 0.5378085304547005; Accuracy: 0.831\n",
      "epoch: 14 Cost: 0.5285980749459842; Accuracy: 0.839\n",
      "epoch: 15 Cost: 0.5468053362925078; Accuracy: 0.831\n",
      "epoch: 16 Cost: 0.519479496215169; Accuracy: 0.835\n",
      "epoch: 17 Cost: 0.5414510654845545; Accuracy: 0.817\n",
      "epoch: 18 Cost: 0.5435878797447209; Accuracy: 0.824\n",
      "epoch: 19 Cost: 0.5196306721869642; Accuracy: 0.83\n",
      "epoch: 20 Cost: 0.5632401536686565; Accuracy: 0.829\n",
      "epoch: 21 Cost: 0.5541117887100762; Accuracy: 0.831\n",
      "epoch: 22 Cost: 0.5050500211952224; Accuracy: 0.841\n",
      "epoch: 23 Cost: 0.5134488720103261; Accuracy: 0.845\n",
      "epoch: 24 Cost: 0.5341131851512141; Accuracy: 0.824\n",
      "epoch: 25 Cost: 0.5043033303293964; Accuracy: 0.835\n",
      "epoch: 26 Cost: 0.5285596405692671; Accuracy: 0.826\n",
      "epoch: 27 Cost: 0.545620295180044; Accuracy: 0.84\n",
      "epoch: 28 Cost: 0.4852136706354878; Accuracy: 0.86\n",
      "epoch: 29 Cost: 0.48691036067816124; Accuracy: 0.855\n",
      "epoch: 30 Cost: 0.5166420025833846; Accuracy: 0.821\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train=x_train, y_train=y_train, batch_size=8, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 Cost: 12.430485487031339; Accuracy: 0.09\n",
      "epoch: 2 Cost: 7.058114637196088; Accuracy: 0.34\n",
      "epoch: 3 Cost: 9.563515669064163; Accuracy: 0.221\n",
      "epoch: 4 Cost: 8.412969447925844; Accuracy: 0.255\n",
      "epoch: 5 Cost: 3.0115268679996907; Accuracy: 0.662\n",
      "epoch: 6 Cost: 2.947973030712882; Accuracy: 0.689\n",
      "epoch: 7 Cost: 2.227599891012284; Accuracy: 0.726\n",
      "epoch: 8 Cost: 3.333884802108879; Accuracy: 0.653\n",
      "epoch: 9 Cost: 2.461473244895727; Accuracy: 0.684\n",
      "epoch: 10 Cost: 2.8613861439187676; Accuracy: 0.66\n",
      "epoch: 11 Cost: 2.922977847635642; Accuracy: 0.691\n",
      "epoch: 12 Cost: 1.8385285283149055; Accuracy: 0.753\n",
      "epoch: 13 Cost: 2.020959023460517; Accuracy: 0.731\n",
      "epoch: 14 Cost: 2.623518472196792; Accuracy: 0.683\n",
      "epoch: 15 Cost: 1.95329307160067; Accuracy: 0.731\n",
      "epoch: 16 Cost: 1.6670461358614561; Accuracy: 0.759\n",
      "epoch: 17 Cost: 1.7597613766971236; Accuracy: 0.725\n",
      "epoch: 18 Cost: 1.7348212004789125; Accuracy: 0.732\n",
      "epoch: 19 Cost: 1.2815610758697016; Accuracy: 0.783\n",
      "epoch: 20 Cost: 2.040128011845826; Accuracy: 0.702\n",
      "epoch: 21 Cost: 1.558474591524889; Accuracy: 0.766\n",
      "epoch: 22 Cost: 1.3569197126868544; Accuracy: 0.76\n",
      "epoch: 23 Cost: 1.9740658928717607; Accuracy: 0.713\n",
      "epoch: 24 Cost: 1.1497749646875195; Accuracy: 0.781\n",
      "epoch: 25 Cost: 2.4814158207166694; Accuracy: 0.666\n",
      "epoch: 26 Cost: 0.878102192678063; Accuracy: 0.82\n",
      "epoch: 27 Cost: 1.124996689787602; Accuracy: 0.798\n",
      "epoch: 28 Cost: 1.1260547255989077; Accuracy: 0.78\n",
      "epoch: 29 Cost: 1.0892312921246747; Accuracy: 0.788\n",
      "epoch: 30 Cost: 2.680810803756215; Accuracy: 0.664\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(28, 28, 1))\n",
    "conv2d1 = Layer.Conv2D(filters=32, kernel_size=3, padding=1, activation='LeakyReLU', prev_layer=input)\n",
    "maxpooling1 = Layer.MaxPool2D(pool_size=2, prev_layer=conv2d1)\n",
    "conv2d2 = Layer.Conv2D(filters=64, kernel_size=3, padding=1, activation='LeakyReLU', prev_layer=maxpooling1)\n",
    "maxpooling2 = Layer.MaxPool2D(pool_size=2, prev_layer=conv2d2)\n",
    "\n",
    "flatten = Layer.Flatten(prev_layer=maxpooling2)\n",
    "layer1 = Layer.Layer(shape=128, activation='LeakyReLU', prev_layer=flatten)\n",
    "output = Layer.Layer(shape=10, activation='softmax', prev_layer=layer1)\n",
    "model = Model(input=input, output=output)\n",
    "model.compile(loss=Loss.CrossEntropy, optimizer=Optimizers.SGD(learning_rate=0.001))\n",
    "\n",
    "model.fit(x_train=x_train, y_train=y_train, batch_size=8, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.61 GiB for an array with shape (60000, 28, 28, 16) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, output\u001b[38;5;241m=\u001b[39moutput)\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mLoss\u001b[38;5;241m.\u001b[39mCrossEntropy, optimizer\u001b[38;5;241m=\u001b[39mOptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m))\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\DNN.py:96\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x_train, y_train, batch_size, epochs, iters, verbose)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m batch_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 96\u001b[0m         y_predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m((\u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m batch_num)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mevaluation(y_predict, y_train)\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28mprint\u001b[39m(s)\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\DNN.py:108\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_test):\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mload_input(X_test)\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39ma\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\DNN.py:24\u001b[0m, in \u001b[0;36mInput.feed_forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\Layer.py:189\u001b[0m, in \u001b[0;36mConv2D.feed_forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m         jj \u001b[38;5;241m=\u001b[39m j\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz[:,ii,jj,:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((tmp \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw), axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__activate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m#print('conv:', np.mean(self.a[0][0]))\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_layer:\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\Layer.py:144\u001b[0m, in \u001b[0;36mConv2D.__activate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLeakyReLU\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.61 GiB for an array with shape (60000, 28, 28, 16) and data type float64"
     ]
    }
   ],
   "source": [
    "from DNN import *\n",
    "\n",
    "input = Input(shape=(28, 28, 1))\n",
    "conv2d1 = Layer.Conv2D(filters=16, kernel_size=3, padding=1, activation='LeakyReLU', prev_layer=input)\n",
    "maxpooling1 = Layer.MaxPool2D(pool_size=2, prev_layer=conv2d1)\n",
    "conv2d2 = Layer.Conv2D(filters=32, kernel_size=3, padding=1, activation='LeakyReLU', prev_layer=maxpooling1)\n",
    "maxpooling2 = Layer.MaxPool2D(pool_size=2, prev_layer=conv2d2)\n",
    "\n",
    "flatten = Layer.Flatten(prev_layer=maxpooling2)\n",
    "layer1 = Layer.Layer(shape=64, activation='LeakyReLU', prev_layer=flatten)\n",
    "output = Layer.Layer(shape=10, activation='softmax', prev_layer=layer1)\n",
    "model = Model(input=input, output=output)\n",
    "model.compile(loss=Loss.CrossEntropy, optimizer=Optimizers.SGD(learning_rate=0.001, momentum=0.9))\n",
    "\n",
    "model.fit(x_train=x_train, y_train=y_train, batch_size=8, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.994512270563088; Accuracy: 0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(497.256135281544, 0.88)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 Cost: 4.033013151364818; Accuracy: 0.228\n",
      "epoch: 2 Cost: 2.7534813890839964; Accuracy: 0.353\n",
      "epoch: 3 Cost: 1.3716653332802045; Accuracy: 0.523\n",
      "epoch: 4 Cost: 1.804027973785816; Accuracy: 0.577\n",
      "epoch: 5 Cost: 0.770537443010531; Accuracy: 0.758\n",
      "epoch: 6 Cost: 1.3297985732677335; Accuracy: 0.657\n",
      "epoch: 7 Cost: 1.2980447344551738; Accuracy: 0.596\n",
      "epoch: 8 Cost: 1.4598646514894822; Accuracy: 0.596\n",
      "epoch: 9 Cost: 0.8449716871586115; Accuracy: 0.744\n",
      "epoch: 10 Cost: 1.835254918259697; Accuracy: 0.614\n",
      "epoch: 11 Cost: 0.8967183936968182; Accuracy: 0.736\n",
      "epoch: 12 Cost: 2.8367623571096283; Accuracy: 0.507\n",
      "epoch: 13 Cost: 0.8482473474600469; Accuracy: 0.734\n",
      "epoch: 14 Cost: 2.4198851065473757; Accuracy: 0.428\n",
      "epoch: 15 Cost: 1.102505721794885; Accuracy: 0.707\n",
      "epoch: 16 Cost: 1.4856817251105414; Accuracy: 0.672\n",
      "epoch: 17 Cost: 1.4047122004739419; Accuracy: 0.686\n",
      "epoch: 18 Cost: 1.763197704281328; Accuracy: 0.75\n",
      "epoch: 19 Cost: 1.3674467282876912; Accuracy: 0.685\n",
      "epoch: 20 Cost: 1.337393746450547; Accuracy: 0.677\n",
      "epoch: 21 Cost: 1.3076691198237944; Accuracy: 0.7\n",
      "epoch: 22 Cost: 1.986183367703683; Accuracy: 0.623\n",
      "epoch: 23 Cost: 0.8492523400003321; Accuracy: 0.77\n",
      "epoch: 24 Cost: 1.4287005101925088; Accuracy: 0.682\n",
      "epoch: 25 Cost: 0.616491170355178; Accuracy: 0.83\n",
      "epoch: 26 Cost: 0.9058837935059183; Accuracy: 0.761\n",
      "epoch: 27 Cost: 1.9839031860659644; Accuracy: 0.709\n",
      "epoch: 28 Cost: 0.65667666851627; Accuracy: 0.816\n",
      "epoch: 29 Cost: 1.2481565136216162; Accuracy: 0.717\n",
      "epoch: 30 Cost: 0.7677311669229833; Accuracy: 0.799\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(28, 28, 1))\n",
    "conv2d1 = Layer.Conv2D(filters=16, kernel_size=3, padding=1, activation='LeakyReLU', prev_layer=input)\n",
    "maxpooling1 = Layer.MaxPool2D(pool_size=2, prev_layer=conv2d1)\n",
    "conv2d2 = Layer.Conv2D(filters=32, kernel_size=3, padding=1, activation='LeakyReLU', prev_layer=maxpooling1)\n",
    "maxpooling2 = Layer.MaxPool2D(pool_size=2, prev_layer=conv2d2)\n",
    "\n",
    "flatten = Layer.Flatten(prev_layer=maxpooling2)\n",
    "layer1 = Layer.Layer(shape=64, activation='LeakyReLU', prev_layer=flatten)\n",
    "output = Layer.Layer(shape=10, activation='softmax', prev_layer=layer1)\n",
    "model = Model(input=input, output=output)\n",
    "model.compile(loss=Loss.CrossEntropy, optimizer=Optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "model.fit(x_train=x_train, y_train=y_train, batch_size=8, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.8521784769143351; Accuracy: 0.76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426.08923845716754, 0.76)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 Cost: 0.5613114959931246; Accuracy: 0.837\n",
      "epoch: 2 Cost: 0.5335168914903441; Accuracy: 0.844\n",
      "epoch: 3 Cost: 1.8144776415993287; Accuracy: 0.735\n",
      "epoch: 4 Cost: 1.4020476201294159; Accuracy: 0.76\n",
      "epoch: 5 Cost: 1.170941065390366; Accuracy: 0.722\n",
      "epoch: 6 Cost: 0.7312885831645125; Accuracy: 0.786\n",
      "epoch: 7 Cost: 1.0171755293217164; Accuracy: 0.766\n",
      "epoch: 8 Cost: 0.7437087312371692; Accuracy: 0.821\n",
      "epoch: 9 Cost: 0.7638867312634743; Accuracy: 0.81\n",
      "epoch: 10 Cost: 1.303892787923893; Accuracy: 0.709\n",
      "epoch: 11 Cost: 0.6088061030260036; Accuracy: 0.812\n",
      "epoch: 12 Cost: 0.45310301480187587; Accuracy: 0.87\n",
      "epoch: 13 Cost: 1.010461050127136; Accuracy: 0.733\n",
      "epoch: 14 Cost: 0.6234866970861792; Accuracy: 0.827\n",
      "epoch: 15 Cost: 1.090111766656975; Accuracy: 0.774\n",
      "epoch: 16 Cost: 0.6642262482253635; Accuracy: 0.821\n",
      "epoch: 17 Cost: 0.6532484841668993; Accuracy: 0.837\n",
      "epoch: 18 Cost: 0.6405055047768028; Accuracy: 0.827\n",
      "epoch: 19 Cost: 0.5581806971494343; Accuracy: 0.833\n",
      "epoch: 20 Cost: 0.5519686350242861; Accuracy: 0.833\n",
      "epoch: 21 Cost: 0.419863304881418; Accuracy: 0.865\n",
      "epoch: 22 Cost: 0.6489019283672967; Accuracy: 0.806\n",
      "epoch: 23 Cost: 0.5073794658740381; Accuracy: 0.855\n",
      "epoch: 24 Cost: 0.6071732042516157; Accuracy: 0.817\n",
      "epoch: 25 Cost: 0.4266965947249382; Accuracy: 0.876\n",
      "epoch: 26 Cost: 0.513025183704991; Accuracy: 0.844\n",
      "epoch: 27 Cost: 0.455111343987948; Accuracy: 0.867\n",
      "epoch: 28 Cost: 0.7172694903855872; Accuracy: 0.79\n",
      "epoch: 29 Cost: 0.6990640691185077; Accuracy: 0.811\n",
      "epoch: 30 Cost: 0.8710901840471303; Accuracy: 0.755\n",
      "Cost: 0.9811411230635486; Accuracy: 0.698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(490.57056153177433, 0.698)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train=x_train, y_train=y_train, batch_size=8, epochs=30)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 Cost: 0.6368870764144824; Accuracy: 0.8006833333333333\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.61 GiB for an array with shape (60000, 28, 28, 16) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, output\u001b[38;5;241m=\u001b[39moutput)\n\u001b[0;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mLoss\u001b[38;5;241m.\u001b[39mCrossEntropy, optimizer\u001b[38;5;241m=\u001b[39mOptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m))\n\u001b[1;32m---> 44\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\DNN.py:95\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x_train, y_train, batch_size, epochs, iters, verbose)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m batch_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m         y_predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m((\u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m batch_num)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mevaluation(y_predict, y_train)\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28mprint\u001b[39m(s)\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\DNN.py:105\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_test):\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mload_input(X_test)\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39ma\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\DNN.py:24\u001b[0m, in \u001b[0;36mInput.feed_forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\Layer.py:196\u001b[0m, in \u001b[0;36mConv2D.feed_forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m         jj \u001b[38;5;241m=\u001b[39m j\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz[:,ii,jj,:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((tmp \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw), axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__activate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m#print('conv:', np.mean(self.a[0][0]))\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_layer:\n",
      "File \u001b[1;32md:\\TickLab-challenge\\TickLab-challenge\\Layer.py:143\u001b[0m, in \u001b[0;36mConv2D.__activate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLeakyReLU\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.61 GiB for an array with shape (60000, 28, 28, 16) and data type float64"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import os \n",
    "from time import time\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "from DNN import *\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float64\") / 255.0\n",
    "x_test  = x_test.astype('float64') / 255.0\n",
    "x_train = tf.convert_to_tensor(x_train)\n",
    "x_test = tf.convert_to_tensor(x_test)\n",
    "x_train = (x_train.numpy())\n",
    "x_test = (x_test.numpy())\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test  = np.expand_dims(x_test , axis=3)\n",
    "\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test  = y_test.reshape(-1)\n",
    "def processing(Y, n):\n",
    "    y = np.zeros((Y.shape[0], n))\n",
    "    for i in range(Y.shape[0]):\n",
    "        y[i, int(Y[i])] = 1\n",
    "    return y\n",
    "\n",
    "y_train = processing(y_train, 10)\n",
    "y_test  = processing(y_test , 10)\n",
    "\n",
    "\n",
    "input = Input(shape=(28, 28, 1))\n",
    "conv2d1 = Layer.Conv2D(filters=16, kernel_size=3, padding=1, activation='LeakyReLU', prev_layer=input)\n",
    "maxpooling1 = Layer.MaxPool2D(pool_size=2, prev_layer=conv2d1)\n",
    "conv2d2 = Layer.Conv2D(filters=32, kernel_size=3, padding=1, activation='LeakyReLU', prev_layer=maxpooling1)\n",
    "maxpooling2 = Layer.MaxPool2D(pool_size=2, prev_layer=conv2d2)\n",
    "\n",
    "flatten = Layer.Flatten(prev_layer=maxpooling2)\n",
    "layer1 = Layer.Layer(shape=64, activation='LeakyReLU', prev_layer=flatten)\n",
    "output = Layer.Layer(shape=10, activation='softmax', prev_layer=layer1)\n",
    "model = Model(input=input, output=output)\n",
    "model.compile(loss=Loss.CrossEntropy, optimizer=Optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "model.fit(x_train=x_train, y_train=y_train, batch_size=32, epochs=20)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
